# Почему DeepSeek в БиоЭкв

## Качество

DeepSeek по международным бенчмаркам сопоставим с топовыми коммерческими моделями и **сильнее** типичных русскоязычных API (GigaChat, YandexGPT) по задачам на рассуждение, математику и структурированный вывод:

| Бенчмарк | DeepSeek-V3 | GPT-4 | Claude 3 |
|----------|-------------|-------|----------|
| **MMLU** (общие знания) | **88,5%** | ~86% | ~85% |
| **Логическая согласованность** | **97,8%** (противоречий 1,1%) | 92,9% (4,8%) | 91,7% (5,2%) |
| **MATH-500** (математика) | **90,2%** | — | ~82% (обычный режим) |
| **AlpacaEval** (следование инструкциям) | **87,6%** | ~57% (GPT-4o-mini) | ~52% (Claude 3.5) |

*Источники: [DeepSeek Benchmarking](https://deepseek.international/benchmarking-deepseek-v3-against-gpt-4-and-claude-3-the-definitive-results/), отчёты 2024–2025.*

Для задач БиоЭкв (извлечение параметров из текста, валидация fuzzy-матчей, генерация разделов синопсиса в JSON) важны именно точность инструкций и непротиворечивость — здесь DeepSeek показывает отличные результаты.

---

## Стоимость API

DeepSeek — один из самых **дешёвых** коммерческих API при сопоставимом качестве:

| Провайдер | Вход (за 1M токенов) | Выход (за 1M токенов) |
|-----------|----------------------|-------------------------|
| **DeepSeek-Chat (V3)** | **$0,14–0,28** | **$0,38–0,42** |
| OpenAI GPT-4o | $5 | $15 |
| OpenAI GPT-4 Turbo | $10 | $30 |
| Google Gemini (Pro) | ~$1,25–3,50 | ~$5–10,50 |
| Claude (Sonnet) | ~$3 | ~$15 |

*Данные 2024–2025, актуальные у провайдеров.*

**Итог:** в 10–50+ раз дешевле OpenAI/Google/Anthropic при уровне качества, достаточном для наших сценариев.

---

## Безопасность данных: альтернатива облачному API

Если **нельзя отправлять данные** (препараты, тексты ОХЛП, реестр) во внешний API, возможны два пути:

1. **Оставить DeepSeek**, но развернуть его **у себя**: модели DeepSeek-V3 и DeepSeek-R1 открыты (в т.ч. под лицензией MIT), их можно поднять на своей инфраструктуре (vLLM, Hugging Face, собственный кластер с GPU).
2. **Заменить на другие open-source модели** того же класса:
   - **Qwen** (Qwen2.5, Qwen3) — сильные рассуждение и длинный контекст (до 1M токенов);
   - **Llama** (Meta) — широко используется, хорошая экосистема;
   - **Moonshot / Kimi** (K1 и др.) — сильные модели с длинным контекстом.

Все перечисленные можно развернуть локально или в своём облаке: данные не уходят к третьим сторонам, стоимость — только железо и электричество.

---

## В БиоЭкв

- Сейчас используется **DeepSeek API** (`deepseek-chat`) как баланс качества и цены.
- Для чувствительных данных при необходимости можно переключиться на **self-hosted DeepSeek, Qwen или Llama** без изменения общей схемы (те же промпты и JSON-формат ответов).
